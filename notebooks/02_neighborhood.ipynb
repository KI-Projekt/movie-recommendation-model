{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/I549511/.pyenv/versions/3.10.13/lib/python3.10/site-packages (24.1.1)\n",
      "Collecting pip\n",
      "  Downloading pip-24.1.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-24.1.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.1.1\n",
      "    Uninstalling pip-24.1.1:\n",
      "      Successfully uninstalled pip-24.1.1\n",
      "Successfully installed pip-24.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /Users/I549511/.pyenv/versions/3.10.13/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/I549511/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/I549511/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/I549511/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/I549511/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pandas) (1.22.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/I549511/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-surprise in /Users/I549511/.pyenv/versions/3.10.13/lib/python3.10/site-packages (1.1.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/I549511/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from scikit-surprise) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/I549511/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from scikit-surprise) (1.22.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/I549511/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from scikit-surprise) (1.7.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install pandas\n",
    "%pip install scikit-surprise\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from surprise import Dataset, Reader, KNNBasic, accuracy\n",
    "from surprise.model_selection import cross_validate, train_test_split, GridSearchCV\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = \"ml-latest-small\"\n",
    "DATA_URL = f\"https://files.grouplens.org/datasets/movielens/{DATA_FILE}.zip\"\n",
    "DATA_DIR = \"../data\"\n",
    "\n",
    "ratings_path = os.path.join(DATA_DIR, DATA_FILE, \"ratings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_ratings_df():\n",
    "    \"\"\"\n",
    "    This function loads the ratings from disk.\n",
    "\n",
    "    Returns:\n",
    "    - ratings_df: The ratings dataframe\n",
    "    \"\"\"\n",
    "    # Check if the directory exists, if not, create it\n",
    "    if not os.path.exists(DATA_DIR):\n",
    "        os.makedirs(DATA_DIR)\n",
    "\n",
    "    data_path = os.path.join(DATA_DIR, f\"{DATA_FILE}.zip\")\n",
    "\n",
    "    if not os.path.exists(data_path):\n",
    "        print(\"Downloading data...\")\n",
    "        urllib.request.urlretrieve(DATA_URL, data_path)\n",
    "        with zipfile.ZipFile(data_path, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(DATA_DIR)\n",
    "\n",
    "    ratings_df = pd.read_csv(ratings_path)\n",
    "    return ratings_df\n",
    "\n",
    "\n",
    "def _load_ratings():\n",
    "    \"\"\"\n",
    "    This function loads the ratings from disk.\n",
    "\n",
    "    Returns:\n",
    "    - train_set: The training set\n",
    "    - test_set: The test set\n",
    "    \"\"\"\n",
    "\n",
    "    ratings_df = _load_ratings_df()\n",
    "    reader = Reader(line_format=\"user item rating timestamp\", sep=\",\")\n",
    "    data = Dataset.load_from_df(ratings_df[[\"userId\", \"movieId\", \"rating\"]], reader)\n",
    "    train_set, test_set = train_test_split(data, test_size=0.3, random_state=42)\n",
    "    return data, train_set, test_set\n",
    "\n",
    "\n",
    "full_data, train_set, test_set = _load_ratings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "What data exploration methods do we need?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering - Neighborhood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "[{'movieId': 4, 'score': 58, 'externalId': 'tt0114709', 'title': 'Toy Story', 'year': 1995}, {'movieId': 5, 'score': 56, 'externalId': 'tt0113497', 'title': 'Jumanji', 'year': 1995}, {'movieId': 6, 'score': 67, 'externalId': 'tt0113228', 'title': 'Grumpier', 'year': 1995}]\n"
     ]
    }
   ],
   "source": [
    "# Wir müssen bei jedem neuen Nutzer neu trainieren --> nicht effizient\n",
    "# Das Dataset ist zu groß für die Speicherung in einer Variable -> Speicherprobleme bei großen Datensätzen -> nicht möglich\n",
    "user = [\n",
    "    {\"movieId\": 1, \"rating\": 5, \"externalId\": \"tt0114709\", \"title\": \"Toy Story\", \"year\": 1995},\n",
    "    {\"movieId\": 2, \"rating\": 3, \"externalId\": \"tt0113497\", \"title\": \"Jumanji\", \"year\": 1995},\n",
    "    {\"movieId\": 3, \"rating\": 4, \"externalId\": \"tt0113228\", \"title\": \"Grumpier\", \"year\": 1995},\n",
    "]\n",
    "\n",
    "movie_list = [{\"movieId\": 4, \"externalId\": \"tt0114709\", \"title\": \"Toy Story\", \"year\": 1995},\n",
    "                {\"movieId\": 5, \"externalId\": \"tt0113497\", \"title\": \"Jumanji\", \"year\": 1995},\n",
    "                {\"movieId\": 6, \"externalId\": \"tt0113228\", \"title\": \"Grumpier\", \"year\": 1995}]\n",
    "\n",
    "\n",
    "def train_model(trainset):\n",
    "    model = KNNBasic(k=50, sim_options={\"name\": \"msd\", \"user_based\": False})\n",
    "    model.fit(trainset)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_neighborhood_based_recommendations(user_ratings, cinema_movies, model):\n",
    "    \"\"\"\n",
    "    This function makes recommendations using neighborhood-based collaborative filtering.\n",
    "\n",
    "    Args:\n",
    "    - user_ratings: The user ratings\n",
    "    - cinema_movies: The cinema movies\n",
    "    - model: The neighborhood-based model\n",
    "\n",
    "    Returns:\n",
    "    - scores: The scores for the cinema movies\n",
    "    \"\"\"\n",
    "\n",
    "    def _find_nearest_neighbors(user_rated_movies, n_similar=1):\n",
    "        \"\"\"\n",
    "        Find a similar user based on the given user's ratings using a pre-trained KNNBasic model.\n",
    "\n",
    "        Parameters:\n",
    "        user_rated_movies (list of dicts): List of ratings by the user in the form [{'movieId': int, 'rating': float}].\n",
    "        model (KNNBasic): The pre-trained Surprise KNNBasic model.\n",
    "        n_similar (int): The number of similar users to find. Default is 1.\n",
    "\n",
    "        Returns:\n",
    "        list: List of similar user IDs.\n",
    "        \"\"\"\n",
    "        # Step 1: Load the Data\n",
    "        data = pd.read_csv(\"../data/ml-latest-small/ratings.csv\")\n",
    "\n",
    "        # Step 2: Create a User-Item Matrix\n",
    "        ratings_matrix = data.pivot_table(\n",
    "            index=\"userId\", columns=\"movieId\", values=\"rating\", fill_value=0\n",
    "        )\n",
    "\n",
    "        # Prepare the new user's ratings\n",
    "        new_user_ratings = pd.Series(index=ratings_matrix.columns)\n",
    "\n",
    "        for movie in user_rated_movies:\n",
    "            movie_id = movie[\"movieId\"]  # Use movieId to match the column\n",
    "            new_user_ratings[movie_id] = movie[\"rating\"]\n",
    "\n",
    "        # Convert the Series to a DataFrame to append it\n",
    "        new_user_df = pd.DataFrame([new_user_ratings.fillna(0)])\n",
    "\n",
    "        # Append the new user's ratings to the ratings_matrix using pd.concat\n",
    "        ratings_matrix = pd.concat([ratings_matrix, new_user_df], ignore_index=True)\n",
    "\n",
    "        # Convert the updated DataFrame to a numpy array for similarity computation\n",
    "        ratings_matrix_np = ratings_matrix.to_numpy()\n",
    "\n",
    "        # Compute cosine similarities with the updated matrix\n",
    "        user_similarities = cosine_similarity(ratings_matrix_np)\n",
    "\n",
    "        # The new user is the last row in the matrix\n",
    "        input_user_index = len(ratings_matrix_np) - 1\n",
    "        input_user_similarity = user_similarities[input_user_index]\n",
    "\n",
    "        # Ignore the similarity of the user to themselves by setting it to -1\n",
    "        input_user_similarity[input_user_index] = -1\n",
    "\n",
    "        # Find the nearest user\n",
    "        nearest_user_index = np.argmax(input_user_similarity)\n",
    "        return nearest_user_index\n",
    "\n",
    "    nearest_user_id = _find_nearest_neighbors(user_ratings, n_similar=1)\n",
    "    results = []\n",
    "\n",
    "    for movie in cinema_movies:\n",
    "        res = model.predict(nearest_user_id, movie[\"movieId\"])\n",
    "        results.append(\n",
    "            {\n",
    "                \"movieId\": movie[\"movieId\"],\n",
    "                \"score\": round(res.est * 20),\n",
    "                \"externalId\": movie[\"externalId\"],\n",
    "                \"title\": movie[\"title\"],\n",
    "                \"year\": movie[\"year\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "model = train_model(train_set)\n",
    "results = make_neighborhood_based_recommendations(user, movie_list, model)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9111  0.8996  0.9117  0.9101  0.9026  0.9070  0.0050  \n",
      "MAE (testset)     0.6980  0.6924  0.7021  0.7015  0.6961  0.6980  0.0036  \n",
      "Fit time          1.52    1.36    1.31    1.33    1.30    1.36    0.08    \n",
      "Test time         3.27    3.05    3.00    3.19    3.39    3.18    0.14    \n",
      "Durchschnittlicher RMSE über 5-Folds: 0.9070271570287334\n",
      "Durchschnittlicher MAE über 5-Folds: 0.6980303290543046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9070271570287334"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _cross_validate_model(dataset, algo, n_splits=5):\n",
    "    \"\"\"\n",
    "    Führt eine Kreuzvalidierung für ein gegebenes Modell mit Surprise durch und berechnet den durchschnittlichen RMSE.\n",
    "\n",
    "    :param dataset: Der Surprise-Datensatz.\n",
    "    :param algo: Das Modell, das validiert werden soll.\n",
    "    :param n_splits: Die Anzahl der Folds für die Kreuzvalidierung.\n",
    "    :return: Der durchschnittliche RMSE über alle Folds.\n",
    "    \"\"\"\n",
    "    # Führe die Kreuzvalidierung durch\n",
    "    results = cross_validate(\n",
    "        algo, dataset, measures=[\"RMSE\", \"MAE\"], cv=n_splits, verbose=True\n",
    "    )\n",
    "\n",
    "    # Durchschnittlicher RMSE über alle Folds\n",
    "    avg_rmse = results[\"test_rmse\"].mean()\n",
    "    print(f\"Durchschnittlicher RMSE über {n_splits}-Folds: {avg_rmse}\")\n",
    "\n",
    "    # Durchschnittlicher MAE über alle Folds\n",
    "    avg_mae = results[\"test_mae\"].mean()\n",
    "    print(f\"Durchschnittlicher MAE über {n_splits}-Folds: {avg_mae}\")\n",
    "\n",
    "    return avg_rmse\n",
    "\n",
    "\n",
    "algo = KNNBasic(k=50, sim_options={\"name\": \"msd\", \"user_based\": False})\n",
    "\n",
    "# Rufe die Funktion mit dem DataFrame und dem SVD-Modell als Argumenten auf\n",
    "_cross_validate_model(full_data, algo, n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _do_a_grid_search(dataset):\n",
    "    \"\"\"\n",
    "    This function does a grid search to find the best hyperparameters for the neighborhood.\n",
    "    \"\"\"\n",
    "    trainset, testset = train_test_split(dataset, test_size=0.2)\n",
    "    param_grid = {\n",
    "        \"k\": [10, 20, 30, 40, 50],\n",
    "        \"sim_options\": {\n",
    "            \"name\": [\"cosine\", \"pearson\", \"msd\", \"pearson_baseline\"],\n",
    "            \"user_based\": [True, False],\n",
    "        },\n",
    "    }\n",
    "    grid_search = GridSearchCV(KNNBasic, param_grid, measures=[\"rmse\"], cv=3)\n",
    "    grid_search.fit(dataset)\n",
    "    print(grid_search.best_params[\"rmse\"])\n",
    "    print(grid_search.best_score[\"rmse\"])\n",
    "\n",
    "    # Bewertung auf Testdaten\n",
    "    best_params = grid_search.best_params[\"rmse\"]\n",
    "    algo = KNNBasic(k=best_params[\"k\"])\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    test_rmse = accuracy.rmse(predictions)\n",
    "    print(f\"RMSE auf Testdaten: {test_rmse}\")\n",
    "\n",
    "    model = KNNBasic(**grid_search.best_params[\"rmse\"], random_state=0)\n",
    "    _cross_validate_model(\n",
    "        dataset,\n",
    "        model,\n",
    "        n_splits=5,\n",
    "    )\n",
    "\n",
    "\n",
    "#_do_a_grid_search(full_data)\n",
    "# RESULTS:\n",
    "# {'k': 50, 'sim_options': {'name': 'msd', 'user_based': False}}\n",
    "# RMSE 0.9125206230768649\n",
    "# RMSE auf Testdaten: 0.9461385511621797\n",
    "# Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
    "# RMSE (testset)    0.9009  0.9042  0.9090  0.9145  0.9054  0.9068  0.0046  \n",
    "# MAE (testset)     0.6966  0.6952  0.7005  0.6997  0.6959  0.6976  0.0021  \n",
    "# Fit time          2.59    3.08    2.59    2.53    2.57    2.67    0.21    \n",
    "# Test time         7.03    7.65    6.94    6.93    6.88    7.09    0.29    \n",
    "# Durchschnittlicher RMSE über 5-Folds: 0.9067951057251864\n",
    "# Durchschnittlicher MAE über 5-Folds: 0.6975876336839881"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item Based vs. User Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item-based:\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9085  0.9016  0.9079  0.9076  0.9108  0.9073  0.0030  \n",
      "MAE (testset)     0.6991  0.6934  0.7001  0.6973  0.7012  0.6982  0.0027  \n",
      "Fit time          1.48    1.37    1.29    1.44    1.36    1.39    0.06    \n",
      "Test time         3.08    2.98    3.02    2.96    3.14    3.04    0.07    \n",
      "Durchschnittlicher RMSE über 5-Folds: 0.9072672650647838\n",
      "Durchschnittlicher MAE über 5-Folds: 0.6982253262843163\n",
      "User-based:\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9468  0.9473  0.9473  0.9513  0.9588  0.9503  0.0046  \n",
      "MAE (testset)     0.7282  0.7279  0.7241  0.7297  0.7353  0.7290  0.0036  \n",
      "Fit time          0.03    0.04    0.04    0.04    0.04    0.04    0.00    \n",
      "Test time         0.59    0.65    0.58    0.65    0.66    0.63    0.03    \n",
      "Durchschnittlicher RMSE über 5-Folds: 0.9503214921027773\n",
      "Durchschnittlicher MAE über 5-Folds: 0.7290486125435135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9503214921027773"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_item_based = KNNBasic(k=50, sim_options={\"name\": \"msd\", \"user_based\": False})\n",
    "algo_user_based = KNNBasic(k=50, sim_options={\"name\": \"msd\", \"user_based\": True})\n",
    "\n",
    "print(\"Item-based:\")\n",
    "_cross_validate_model(full_data, algo_item_based, n_splits=5)\n",
    "\n",
    "print(\"User-based:\")\n",
    "_cross_validate_model(full_data, algo_user_based, n_splits=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
