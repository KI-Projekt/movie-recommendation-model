{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pprint import pprint\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split as sk_train_test_split\n",
    "\n",
    "\n",
    "def make_recommendations(user_ratings_input, cinema_movies_input, is_evaluation, weights):\n",
    "    \"\"\"\n",
    "    This function makes movie recommendations for a user.\n",
    "\n",
    "    Args:\n",
    "    - user_ratings_input: The user ratings\n",
    "    - cinema_movies_input: The cinema movies\n",
    "    - is_evaluation: A flag indicating whether the function is being called for evaluation\n",
    "\n",
    "    Returns:\n",
    "    - sorted_scores: The sorted scores for the cinema movies\n",
    "    \"\"\"\n",
    "    neighborhood_model, matrix_factorization_model = _get_trained_models()\n",
    "\n",
    "    weight_content_based = weights[0]\n",
    "    weight_neighborhood_based = weights[1]\n",
    "    weight_matrix_factorization = weights[2]\n",
    "\n",
    "    if is_evaluation:\n",
    "        user_ratings = user_ratings_input\n",
    "        cinema_movies = cinema_movies_input\n",
    "    else:\n",
    "        user_ratings, cinema_movies = _map_movie_ids(\n",
    "            user_ratings_input, cinema_movies_input\n",
    "        )\n",
    "\n",
    "    scores_content_based = make_content_based_recommendations(\n",
    "        user_ratings, cinema_movies\n",
    "    )\n",
    "    scores_neighborhood_based = make_neighborhood_based_recommendations(\n",
    "        user_ratings, cinema_movies, neighborhood_model\n",
    "    )\n",
    "    scores_matrix_factorization = make_matrix_factorization_recommendations(\n",
    "        user_ratings, cinema_movies, matrix_factorization_model\n",
    "    )\n",
    "\n",
    "    scores = _combine_recommendations(\n",
    "        scores_content_based,\n",
    "        scores_neighborhood_based,\n",
    "        scores_matrix_factorization,\n",
    "        weight_content_based,\n",
    "        weight_neighborhood_based,\n",
    "        weight_matrix_factorization,\n",
    "    )\n",
    "\n",
    "    sorted_scores = sorted(scores, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    return sorted_scores\n",
    "\n",
    "\n",
    "def make_content_based_recommendations(user_ratings_input, cinema_movies_input):\n",
    "    \"\"\"\n",
    "    This function makes recommendations using content-based filtering.\n",
    "\n",
    "    Args:\n",
    "    - user_ratings: The user ratings\n",
    "    - cinema_movies: The cinema movies\n",
    "\n",
    "    Returns:\n",
    "    - scores: The scores for the cinema movies\n",
    "    \"\"\"\n",
    "\n",
    "    def _load_data():\n",
    "        movies = pd.read_csv(\"../data/ml-latest-small/movies.csv\")\n",
    "        movies_with_genres = pd.read_csv(\"../data/movies_with_genres.csv\")\n",
    "        movies_with_year = pd.read_csv(\"../data/movies_with_year.csv\", sep=\";\")\n",
    "\n",
    "        # Extrahiere das Erscheinungsjahr aus dem Titel und füge es als neue Spalte hinzu\n",
    "        movies[\"year\"] = movies[\"title\"].str.extract(r\"\\((\\d{4})\\)\")\n",
    "\n",
    "        # Entferne das Erscheinungsjahr aus dem Titel\n",
    "        movies[\"title\"] = movies[\"title\"].str.replace(r\"\\s*\\(\\d{4}\\)\", \"\", regex=True)\n",
    "        return movies, movies_with_genres, movies_with_year\n",
    "\n",
    "    def _handle_missing_years(movies, movies_with_year):\n",
    "        # Füge die fehlenden Jahre aus der neuen CSV-Datei ein, basierend auf den Titeln\n",
    "        movies[\"year\"] = movies.apply(\n",
    "            lambda row: (\n",
    "                movies_with_year[movies_with_year[\"title\"] == row[\"title\"]][\n",
    "                    \"year\"\n",
    "                ].values[0]\n",
    "                if pd.isnull(row[\"year\"])\n",
    "                and row[\"title\"] in movies_with_year[\"title\"].values\n",
    "                else row[\"year\"]\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        # Entferne Filme ohne Erscheinungsjahr\n",
    "        movies = movies.dropna(subset=[\"year\"])\n",
    "        movies.isnull().sum()\n",
    "        return movies\n",
    "\n",
    "    def _prepare_genres(movies, movies_with_genres):\n",
    "        # Zusammenführen der DataFrames basierend auf den Titeln und Jahren\n",
    "        movies_updated = pd.merge(\n",
    "            movies,\n",
    "            movies_with_genres[[\"title\", \"year\", \"genres\"]],\n",
    "            on=[\"title\", \"year\"],\n",
    "            how=\"left\",\n",
    "            suffixes=(\"\", \"_new\"),\n",
    "        )\n",
    "\n",
    "        # Aktualisieren der Genres im movies DataFrame nur für die übereinstimmenden Einträge\n",
    "        movies_updated[\"genres\"] = movies_updated[\"genres_new\"].combine_first(\n",
    "            movies_updated[\"genres\"]\n",
    "        )\n",
    "\n",
    "        # Entferne die temporäre Spalte\n",
    "        movies_updated = movies_updated.drop(columns=[\"genres_new\"])\n",
    "        movies = movies_updated\n",
    "\n",
    "        # Entferne \"(no genres listed)\" aus der Genre-Liste\n",
    "        movies[\"genres\"] = movies[\"genres\"].replace(\"(no genres listed)\", \"\")\n",
    "\n",
    "        # Trenne die Genres in separate Listen\n",
    "        genre_list = movies[\"genres\"].str.split(\"|\")\n",
    "\n",
    "        # Finde alle einzigartigen Genres\n",
    "        all_genres = set(genre for sublist in genre_list for genre in sublist if genre)\n",
    "\n",
    "        # Erstelle für jedes Genre eine Spalte und fülle sie mit binären Werten\n",
    "        for genre in all_genres:\n",
    "            movies[genre] = movies[\"genres\"].apply(lambda x: int(genre in x.split(\"|\")))\n",
    "\n",
    "        # Entferne die ursprüngliche 'genres' Spalte\n",
    "        movies = movies.drop(columns=[\"genres\"])\n",
    "        return movies\n",
    "\n",
    "    def _get_movie_features(movies, movie_id):\n",
    "        filtered_movie = movies[movies[\"movieId\"] == movie_id]\n",
    "        if not filtered_movie.empty:\n",
    "            # Wähle nur die numerischen Spalten aus, die für die Berechnung der Ähnlichkeiten verwendet werden sollen, außer 'movieId'\n",
    "            numeric_features = filtered_movie.drop(columns=[\"movieId\"]).select_dtypes(\n",
    "                include=[np.number]\n",
    "            )\n",
    "            return numeric_features.iloc[0]\n",
    "        else:\n",
    "            print(f\"Movie with ID {movie_id} not found\")\n",
    "            return None\n",
    "\n",
    "    movies, movies_with_genres, movies_with_year = _load_data()\n",
    "    movies = _handle_missing_years(movies, movies_with_year)\n",
    "    movies = _prepare_genres(movies, movies_with_genres)\n",
    "\n",
    "    # Schritt 1: Extrahieren der Merkmale der vom Nutzer bewerteten Filme\n",
    "    user_movie_features = []\n",
    "    has_positive_ratings = any(\n",
    "        \"rating\" in movie and movie[\"rating\"] >= 2.5 for movie in user_ratings_input\n",
    "    )\n",
    "\n",
    "    for movie in user_ratings_input:\n",
    "        if has_positive_ratings and movie.get(\"rating\", 0) >= 2.5:\n",
    "            features = _get_movie_features(movies, movie[\"movieId\"])\n",
    "            if features is not None:\n",
    "                user_movie_features.append(features.values)\n",
    "        elif not has_positive_ratings and movie.get(\"rating\", 0) < 2.5:\n",
    "            features = _get_movie_features(movies, movie[\"movieId\"])\n",
    "            if features is not None:\n",
    "                user_movie_features.append(features.values)\n",
    "\n",
    "    # Schritt 2: Feature-Vektorisierung\n",
    "    if not user_movie_features:\n",
    "        raise ValueError(\"Keine positiv bewerteten Filme vorhanden.\")\n",
    "\n",
    "    user_profile = np.mean(user_movie_features, axis=0)\n",
    "\n",
    "    # Schritt 3: Ähnlichkeitsberechnung\n",
    "    kino_movie_features = []\n",
    "    for kino_movie in cinema_movies_input:\n",
    "        features = _get_movie_features(movies, kino_movie[\"movieId\"])\n",
    "        if features is not None:\n",
    "            kino_movie_features.append(features.values)\n",
    "\n",
    "    if not kino_movie_features:\n",
    "        raise ValueError(\"Keine Kino-Filme mit passenden Features gefunden.\")\n",
    "\n",
    "    similarities = cosine_similarity([user_profile], kino_movie_features)[0]\n",
    "    similarities = similarities * 100\n",
    "\n",
    "    # Schritt 4: Sortierung und Ausgabe\n",
    "    # Falls der Nutzer positive Bewertungen abgegeben hat, sortiere nach absteigender Ähnlichkeit\n",
    "    # Andernfalls sortiere nach aufsteigender Ähnlichkeit\n",
    "    cinema_movies_with_similarity = []\n",
    "    for i, kino_movie in enumerate(cinema_movies_input):\n",
    "        kino_movie_with_similarity = {\n",
    "            \"externalId\": kino_movie[\"externalId\"],\n",
    "            \"title\": kino_movie[\"title\"],\n",
    "            \"year\": kino_movie[\"year\"],\n",
    "            \"score\": similarities[i],\n",
    "            \"movieId\": kino_movie[\"movieId\"],\n",
    "        }\n",
    "        cinema_movies_with_similarity.append(kino_movie_with_similarity)\n",
    "\n",
    "    if has_positive_ratings:\n",
    "        sorted_cinema_movies = sorted(\n",
    "            cinema_movies_with_similarity, key=lambda x: x[\"score\"], reverse=True\n",
    "        )\n",
    "    else:\n",
    "        sorted_cinema_movies = sorted(\n",
    "            cinema_movies_with_similarity, key=lambda x: x[\"score\"]\n",
    "        )\n",
    "\n",
    "    return sorted_cinema_movies\n",
    "\n",
    "\n",
    "def make_neighborhood_based_recommendations(user_ratings, cinema_movies, model):\n",
    "    \"\"\"\n",
    "    This function makes recommendations using neighborhood-based collaborative filtering.\n",
    "\n",
    "    Args:\n",
    "    - user_ratings: The user ratings\n",
    "    - cinema_movies: The cinema movies\n",
    "    - model: The neighborhood-based model\n",
    "\n",
    "    Returns:\n",
    "    - scores: The scores for the cinema movies\n",
    "    \"\"\"\n",
    "\n",
    "    def _find_nearest_neighbors(user_rated_movies, n_similar=1):\n",
    "        \"\"\"\n",
    "        Find a similar user based on the given user's ratings using a pre-trained KNNBasic model.\n",
    "\n",
    "        Parameters:\n",
    "        user_rated_movies (list of dicts): List of ratings by the user in the form [{'movieId': int, 'rating': float}].\n",
    "        model (KNNBasic): The pre-trained Surprise KNNBasic model.\n",
    "        n_similar (int): The number of similar users to find. Default is 1.\n",
    "\n",
    "        Returns:\n",
    "        list: List of similar user IDs.\n",
    "        \"\"\"\n",
    "        # Step 1: Load the Data\n",
    "        data = pd.read_csv(\"../data/ml-latest-small/ratings.csv\")\n",
    "\n",
    "        # Step 2: Create a User-Item Matrix\n",
    "        ratings_matrix = data.pivot_table(\n",
    "            index=\"userId\", columns=\"movieId\", values=\"rating\", fill_value=0\n",
    "        )\n",
    "\n",
    "        # Prepare the new user's ratings\n",
    "        new_user_ratings = pd.Series(index=ratings_matrix.columns)\n",
    "\n",
    "        for movie in user_rated_movies:\n",
    "            movie_id = movie[\"movieId\"]  # Use movieId to match the column\n",
    "            new_user_ratings[movie_id] = movie[\"rating\"]\n",
    "\n",
    "        # Convert the Series to a DataFrame to append it\n",
    "        new_user_df = pd.DataFrame([new_user_ratings.fillna(0)])\n",
    "\n",
    "        # Append the new user's ratings to the ratings_matrix using pd.concat\n",
    "        ratings_matrix = pd.concat([ratings_matrix, new_user_df], ignore_index=True)\n",
    "\n",
    "        # Convert the updated DataFrame to a numpy array for similarity computation\n",
    "        ratings_matrix_np = ratings_matrix.to_numpy()\n",
    "\n",
    "        # Compute cosine similarities with the updated matrix\n",
    "        user_similarities = cosine_similarity(ratings_matrix_np)\n",
    "\n",
    "        # The new user is the last row in the matrix\n",
    "        input_user_index = len(ratings_matrix_np) - 1\n",
    "        input_user_similarity = user_similarities[input_user_index]\n",
    "\n",
    "        # Ignore the similarity of the user to themselves by setting it to -1\n",
    "        input_user_similarity[input_user_index] = -1\n",
    "\n",
    "        # Find the nearest user\n",
    "        nearest_user_index = np.argmax(input_user_similarity)\n",
    "        return nearest_user_index\n",
    "\n",
    "    nearest_user_id = _find_nearest_neighbors(user_ratings, n_similar=1)\n",
    "    results = []\n",
    "\n",
    "    for movie in cinema_movies:\n",
    "        res = model.predict(nearest_user_id, movie[\"movieId\"])\n",
    "        results.append(\n",
    "            {\n",
    "                \"movieId\": movie[\"movieId\"],\n",
    "                \"score\": round(res.est * 20),\n",
    "                \"externalId\": movie[\"externalId\"],\n",
    "                \"title\": movie[\"title\"],\n",
    "                \"year\": movie[\"year\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def make_matrix_factorization_recommendations(user_ratings, cinema_movies, model):\n",
    "    \"\"\"\n",
    "    This function makes recommendations using matrix factorization.\n",
    "\n",
    "    Args:\n",
    "    - user_ratings: The user ratings\n",
    "    - cinema_movies: The cinema movies\n",
    "    - model: The matrix factorization model\n",
    "\n",
    "    Returns:\n",
    "    - scores: The scores for the cinema movies\n",
    "    \"\"\"\n",
    "\n",
    "    def _find_similar_user(user_rated_movies, model, n_similar=1):\n",
    "        \"\"\"\n",
    "        Find a similar user based on the given user's ratings using a pre-trained model.\n",
    "\n",
    "        Parameters:\n",
    "        user_rated_movies (list of dicts): List of ratings by the user in the form [{'movieId': int, 'rating': float}].\n",
    "        model (AlgoBase): The pre-trained Surprise model.\n",
    "        n_similar (int): The number of similar users to find. Default is 1.\n",
    "\n",
    "        Returns:\n",
    "        list: List of similar user IDs.\n",
    "        \"\"\"\n",
    "        # Map movie IDs to the internal item IDs used by the model\n",
    "        trainset = model.trainset\n",
    "        temp_user_ratings = [\n",
    "            (trainset.to_inner_iid(movie[\"movieId\"]), movie[\"rating\"])\n",
    "            for movie in user_rated_movies\n",
    "            if movie[\"movieId\"] in trainset._raw2inner_id_items\n",
    "        ]\n",
    "\n",
    "        # Get the latent factors for the items rated by the temporary user\n",
    "        q_i = np.array([model.qi[item_id] for item_id, _ in temp_user_ratings])\n",
    "        r_ui = np.array([rating for _, rating in temp_user_ratings])\n",
    "\n",
    "        # Calculate the implicit factors (biases can be included if the model uses them)\n",
    "        user_factors = np.linalg.lstsq(q_i, r_ui, rcond=None)[0]\n",
    "\n",
    "        # Calculate the similarity of the temporary user to all other users\n",
    "        similarities = []\n",
    "        for other_inner_user_id in trainset.all_users():\n",
    "            other_user_factors = model.pu[other_inner_user_id]\n",
    "            similarity = np.dot(user_factors, other_user_factors)\n",
    "            similarities.append((similarity, trainset.to_raw_uid(other_inner_user_id)))\n",
    "\n",
    "        # Sort the similarities in descending order and get the top n_similar users\n",
    "        similarities.sort(reverse=True, key=lambda x: x[0])\n",
    "        similar_users = [uid for _, uid in similarities[:n_similar]]\n",
    "\n",
    "        return similar_users[0]\n",
    "\n",
    "    similar_user = _find_similar_user(user_ratings, model, n_similar=1)\n",
    "    results = []\n",
    "\n",
    "    for movie in cinema_movies:\n",
    "        res = model.predict(similar_user, movie[\"movieId\"])\n",
    "        results.append(\n",
    "            {\n",
    "                \"movieId\": movie[\"movieId\"],\n",
    "                \"score\": round(res.est * 20),\n",
    "                \"externalId\": movie[\"externalId\"],\n",
    "                \"title\": movie[\"title\"],\n",
    "                \"year\": movie[\"year\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def _combine_recommendations(\n",
    "    scores_content_based,\n",
    "    scores_neighborhood_based,\n",
    "    scores_matrix_factorization,\n",
    "    weight_content_based,\n",
    "    weight_neighborhood_based,\n",
    "    weight_matrix_factorization,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function combines the scores from the different recommendation methods.\n",
    "\n",
    "    Args:\n",
    "    - scores_content_based: The scores from the content-based recommender\n",
    "    - scores_neighborhood_based: The scores from the neighborhood-based recommender\n",
    "    - scores_matrix_factorization: The scores from the matrix factorization recommender\n",
    "\n",
    "    Returns:\n",
    "    - scores: The combined scores\n",
    "    \"\"\"\n",
    "    # print(\"MATRIX FACTORIZATION\")\n",
    "    # pprint(scores_matrix_factorization)\n",
    "    # print(\"NEIGHBORHOOD BASED\")\n",
    "    # pprint(scores_neighborhood_based)\n",
    "    # print(\"CONTENT BASED\")\n",
    "    # pprint(scores_content_based)\n",
    "    scores = []\n",
    "    for movie in scores_content_based:\n",
    "        # Finden Sie das entsprechende movie in den anderen Listen\n",
    "        neighborhood_movie = next(\n",
    "            (\n",
    "                item\n",
    "                for item in scores_neighborhood_based\n",
    "                if item[\"movieId\"] == movie[\"movieId\"]\n",
    "            ),\n",
    "            None,\n",
    "        )\n",
    "        matrix_movie = next(\n",
    "            (\n",
    "                item\n",
    "                for item in scores_matrix_factorization\n",
    "                if item[\"movieId\"] == movie[\"movieId\"]\n",
    "            ),\n",
    "            None,\n",
    "        )\n",
    "\n",
    "        # Überprüfen Sie, ob das movie in den anderen Listen gefunden wurde\n",
    "        if neighborhood_movie is None or matrix_movie is None:\n",
    "            continue\n",
    "\n",
    "        # Berechnen Sie den Durchschnittsscore\n",
    "        average_score = round(\n",
    "            (\n",
    "                movie[\"score\"] * weight_content_based\n",
    "                + neighborhood_movie[\"score\"] * weight_neighborhood_based\n",
    "                + matrix_movie[\"score\"] * weight_matrix_factorization\n",
    "            )\n",
    "            / (weight_content_based + weight_neighborhood_based + weight_matrix_factorization)\n",
    "        )\n",
    "\n",
    "        scores.append(\n",
    "            {\n",
    "                \"externalId\": movie[\"externalId\"],\n",
    "                \"title\": movie[\"title\"],\n",
    "                \"year\": movie[\"year\"],\n",
    "                \"score\": average_score,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # print(\"AVERAGE SCORE\")\n",
    "    # pprint(scores)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def _get_trained_models():\n",
    "    \"\"\"\n",
    "    This function loads trained models from disk.\n",
    "\n",
    "    Returns:\n",
    "    - neighborhood_model: The trained neighborhood model\n",
    "    - matrix_factorization_model: The trained matrix factorization model\n",
    "    \"\"\"\n",
    "    with open(\"../models/neighborhood_model.pkl\", \"rb\") as f:\n",
    "        neighborhood_model = pickle.load(f)\n",
    "    with open(\"../models/matrix_factorization_model.pkl\", \"rb\") as f:\n",
    "        matrix_factoization_model = pickle.load(f)\n",
    "    return neighborhood_model, matrix_factoization_model\n",
    "\n",
    "\n",
    "def _normalize_title(title):\n",
    "    \"\"\"\n",
    "    This function normalizes the title of a movie.\n",
    "\n",
    "    Args:\n",
    "    - title: The title of the movie\n",
    "\n",
    "    Returns:\n",
    "    - normalized_title: The normalized title\n",
    "    \"\"\"\n",
    "    articles = [\"the\", \"a\", \"an\"]\n",
    "    words = title.strip().split()\n",
    "    if words[-1].strip(\",\").lower() in articles:\n",
    "        return title.strip().lower()\n",
    "    if words[0].lower() in articles:\n",
    "        return \", \".join(words[1:]) + \", \" + words[0].capitalize()\n",
    "    return title.lower()\n",
    "\n",
    "\n",
    "def _alternate_title_format(title):\n",
    "    \"\"\"\n",
    "    This function returns an alternate title format for a movie.\n",
    "\n",
    "    Args:\n",
    "    - title: The title of the movie\n",
    "\n",
    "    Returns:\n",
    "    - alternate_title: The alternate title format\n",
    "    \"\"\"\n",
    "    articles = [\"the\", \"a\", \"an\"]\n",
    "    words = title.strip().split()\n",
    "    if words[0].lower() in articles:\n",
    "        return \", \".join(words[1:]) + \", \" + words[0].capitalize()\n",
    "    if words[-1].strip(\",\").lower() in articles:\n",
    "        return words[-1].capitalize() + \" \" + \" \".join(words[:-1]).replace(\",\", \"\")\n",
    "    return title.lower()\n",
    "\n",
    "\n",
    "# Funktion zur Zuordnung der IDs\n",
    "def _map_movie_ids(user_ratings_input, cinema_movies_input):\n",
    "    \"\"\"\n",
    "    This function maps the movie IDs to the user ratings and cinema movies.\n",
    "\n",
    "    Args:\n",
    "    - user_ratings_input: The user ratings\n",
    "    - cinema_movies_input: The cinema movies\n",
    "\n",
    "    Returns:\n",
    "    - mapped_user_ratings: The user ratings with movie IDs\n",
    "    - mapped_cinema_movies: The cinema movies with movie IDs\n",
    "    \"\"\"\n",
    "    movies_df = pd.read_csv(\"../data/ml-latest-small/movies_processed.csv\")\n",
    "    # Normalisieren der Titelspalte des DataFrames\n",
    "    movies_df[\"normalized_title\"] = movies_df[\"title\"].apply(_normalize_title)\n",
    "    movies_df[\"alternate_title\"] = movies_df[\"title\"].apply(_alternate_title_format)\n",
    "\n",
    "    def get_movie_id(title, year):\n",
    "        normalized_title = _normalize_title(title)\n",
    "        alternate_title = _alternate_title_format(title)\n",
    "\n",
    "        filtered_movies = movies_df[\n",
    "            (\n",
    "                (movies_df[\"normalized_title\"] == normalized_title)\n",
    "                | (movies_df[\"alternate_title\"] == alternate_title)\n",
    "            )\n",
    "            & (movies_df[\"year\"] == year)\n",
    "        ]\n",
    "        if not filtered_movies.empty:\n",
    "            return filtered_movies.iloc[0][\"movieId\"]\n",
    "        else:\n",
    "            print(f\"{title} ({year}) not found\")\n",
    "            return None\n",
    "\n",
    "    # IDs zu den Filmen im user_ratings_input Array hinzufügen\n",
    "    mapped_user_ratings = []\n",
    "    for rating in user_ratings_input:\n",
    "        movie_id = get_movie_id(rating[\"title\"], rating[\"year\"])\n",
    "        mapped_user_ratings.append({**rating, \"movieId\": movie_id})\n",
    "\n",
    "    # IDs zu den Filmen im cinema_movies_input Array hinzufügen\n",
    "    mapped_cinema_movies = []\n",
    "    for movie in cinema_movies_input:\n",
    "        movie_id = get_movie_id(movie[\"title\"], movie[\"year\"])\n",
    "        mapped_cinema_movies.append({**movie, \"movieId\": movie_id})\n",
    "\n",
    "    return mapped_user_ratings, mapped_cinema_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def _evaluate_all(weights):\n",
    "    \"\"\"\n",
    "    This function evaluates the predictions of a trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    def _get_user_ratings_per_user(ratings_df):\n",
    "        user_ratings = {}\n",
    "        for _, row in ratings_df.iterrows():\n",
    "            user_id = row[\"userId\"]\n",
    "            movie_id = row[\"movieId\"]\n",
    "            rating = row[\"rating\"]\n",
    "\n",
    "            if user_id not in user_ratings:\n",
    "                user_ratings[user_id] = []\n",
    "\n",
    "            user_ratings[user_id].append(\n",
    "                {\n",
    "                    \"movieId\": movie_id,\n",
    "                    \"rating\": rating,\n",
    "                    \"title\": \"\",\n",
    "                    \"year\": 1000,\n",
    "                    \"externalId\": str(movie_id),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return user_ratings\n",
    "\n",
    "    ratings_df = pd.read_csv(\"../data/ml-latest-small/test_set_ratings.csv\")\n",
    "    input_data, test_data = sk_train_test_split(\n",
    "        ratings_df, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    user_ratings_input = _get_user_ratings_per_user(test_data)\n",
    "    user_ratings_test = _get_user_ratings_per_user(input_data)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for user_id, user_ratings_input in user_ratings_input.items():\n",
    "        if user_id not in user_ratings_test:\n",
    "            # TODO: Remove from array, that score is calulated correctly\n",
    "            continue\n",
    "\n",
    "        movies_to_test = user_ratings_test[user_id]\n",
    "\n",
    "        score = make_recommendations(user_ratings_input, movies_to_test, True, weights)\n",
    "\n",
    "        user_results = []\n",
    "        for movie in score:\n",
    "            rating_for_movie = next(\n",
    "                (\n",
    "                    test_movie\n",
    "                    for test_movie in movies_to_test\n",
    "                    if test_movie[\"externalId\"] == movie[\"externalId\"]\n",
    "                    and \"rating\" in test_movie\n",
    "                ),\n",
    "                None,\n",
    "            )\n",
    "            user_results.append(\n",
    "                {\n",
    "                    \"score\": movie[\"score\"],\n",
    "                    \"title\": movie[\"title\"],\n",
    "                    \"year\": movie[\"year\"],\n",
    "                    \"externalId\": movie[\"externalId\"],\n",
    "                    \"rating\": rating_for_movie[\"rating\"] * 20,\n",
    "                }\n",
    "            )\n",
    "        results.append({\"userId\": user_id, \"results\": user_results})\n",
    "\n",
    "    def _calculate_rmse(results):\n",
    "        rmse_score = 0\n",
    "        mae_score = 0\n",
    "        ctr = 0\n",
    "        for user_result in results:\n",
    "            for movie in user_result[\"results\"]:\n",
    "                if \"rating\" in movie:\n",
    "                    rmse_score += ((movie[\"rating\"] - movie[\"score\"]) / 20) ** 2\n",
    "                    mae_score += abs(movie[\"rating\"] - movie[\"score\"]) / 20\n",
    "                    ctr += 1\n",
    "        rmse_score = (rmse_score / ctr) ** 0.5\n",
    "        mae_score = mae_score / ctr\n",
    "        print(\"\\nEvaluation results for all models:\")\n",
    "        print(f\"RMSE: {rmse_score}\")\n",
    "        print(f\"MAE: {mae_score}\")\n",
    "        print(\"\\n\")\n",
    "        return rmse_score, mae_score\n",
    "\n",
    "    rmse, mae = _calculate_rmse(results)\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize weights of different models in hybrid model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimale Gewichte (RMSE): [0.00000000e+00 3.74094352e-18 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def find_optimal_weights_rmse_simpler(\n",
    "    mae_model_content_based, mae_model_neighborhood, mae_model_matrix_factorization\n",
    "):\n",
    "    def combined_rmse(weights, rmse):\n",
    "        # Berechne den gewichteten MAE\n",
    "        weighted_mae = np.sum(weights * rmse) / np.sum(weights)\n",
    "        return weighted_mae\n",
    "\n",
    "    # Startwerte für die Gewichte\n",
    "    initial_weights = np.array([1.0, 1.0, 1.0])\n",
    "\n",
    "    # MAE-Werte der Modelle in ein Array packen\n",
    "    rmses = np.array(\n",
    "        [\n",
    "            mae_model_content_based,\n",
    "            mae_model_neighborhood,\n",
    "            mae_model_matrix_factorization,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Optimierung durchführen\n",
    "    result = minimize(\n",
    "        combined_rmse,\n",
    "        initial_weights,\n",
    "        args=(rmses,),\n",
    "        bounds=[(0, None), (0, None), (0, None)],\n",
    "    )\n",
    "\n",
    "    # Optimale Gewichte\n",
    "    optimal_weights = result.x / np.sum(\n",
    "        result.x\n",
    "    )  # Normieren der Gewichte, sodass sie sich auf 1 summieren\n",
    "    return optimal_weights\n",
    "\n",
    "\n",
    "# Beispiel-RMSE-Werte der einzelnen Modelle\n",
    "rmse_model_content_based = 1.72\n",
    "rmse_model_neighborhood = 1.12\n",
    "rmse_model_matrix_factorization = 1.07\n",
    "\n",
    "# Optimale Gewichte berechnen\n",
    "optimal_weights_mae = find_optimal_weights_rmse_simpler(\n",
    "    rmse_model_content_based, rmse_model_neighborhood, rmse_model_matrix_factorization\n",
    ")\n",
    "print(\"Optimale Gewichte (RMSE):\", optimal_weights_mae)\n",
    "# Optimale Gewichte (RMSE): [0.00000000e+00 3.74094352e-18 1.00000000e+00]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimale Gewichte: [0.11270225 0.37353889 0.51375886]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/c9cmt9zd5mn1_1n29y4lkh1c0000gn/T/ipykernel_10814/1613914504.py:10: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  weighted_rmse = np.sqrt(np.sum((weights * rmses) ** 2) / np.sum(weights))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def find_optimal_weights(\n",
    "    rmse_model_content_based, rmse_model_neighborhood, rmse_model_matrix_factorization\n",
    "):\n",
    "    def combined_rmse(weights, rmses):\n",
    "        # Berechne den gewichteten RMSE\n",
    "        weighted_rmse = np.sqrt(np.sum((weights * rmses) ** 2) / np.sum(weights))\n",
    "        return weighted_rmse\n",
    "\n",
    "    # Startwerte für die Gewichte\n",
    "    initial_weights = np.array([1.0, 1.0, 1.0])\n",
    "\n",
    "    # RMSE-Werte der Modelle in ein Array packen\n",
    "    rmses = np.array(\n",
    "        [\n",
    "            rmse_model_content_based,\n",
    "            rmse_model_neighborhood,\n",
    "            rmse_model_matrix_factorization,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Optimierung durchführen\n",
    "    result = minimize(\n",
    "        combined_rmse,\n",
    "        initial_weights,\n",
    "        args=(rmses,),\n",
    "        bounds=[(0, None), (0, None), (0, None)],\n",
    "    )\n",
    "\n",
    "    # Optimale Gewichte\n",
    "    optimal_weights = result.x / np.sum(\n",
    "        result.x\n",
    "    )  # Normieren der Gewichte, sodass sie sich auf 1 summieren\n",
    "    return optimal_weights\n",
    "\n",
    "\n",
    "# Beispiel-RMSE-Werte der einzelnen Modelle\n",
    "rmse_model_content_based = 1.72\n",
    "rmse_model_neighborhood = 1.12\n",
    "rmse_model_matrix_factorization = 1.07\n",
    "\n",
    "# Optimale Gewichte berechnen\n",
    "optimal_weights = find_optimal_weights(\n",
    "    rmse_model_content_based, rmse_model_neighborhood, rmse_model_matrix_factorization\n",
    ")\n",
    "print(\"Optimale Gewichte:\", optimal_weights)\n",
    "# Optimale Gewichte: [0.11270225 0.37353889 0.51375886]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0937656732767416\n",
      "MAE: 0.8858047530951951\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.09376822123241\n",
      "MAE: 0.8858071248991894\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0937612821051712\n",
      "MAE: 0.8857976376832128\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.093763342163165\n",
      "MAE: 0.885802381291201\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0462275324770507\n",
      "MAE: 0.8414733646411412\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0462275324770507\n",
      "MAE: 0.8414733646411412\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0462275324770507\n",
      "MAE: 0.8414733646411412\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0462275324770507\n",
      "MAE: 0.8414733646411412\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0710114310819794\n",
      "MAE: 0.8653835207058447\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0710114310819794\n",
      "MAE: 0.8653835207058447\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0710114310819794\n",
      "MAE: 0.8653835207058447\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0710114310819794\n",
      "MAE: 0.8653835207058447\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.084841881510452\n",
      "MAE: 0.87774536312319\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.084841881510452\n",
      "MAE: 0.87774536312319\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.084841881510452\n",
      "MAE: 0.87774536312319\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.084841881510452\n",
      "MAE: 0.87774536312319\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0906357170269454\n",
      "MAE: 0.883070063089981\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0906357170269454\n",
      "MAE: 0.883070063089981\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0906357170269454\n",
      "MAE: 0.883070063089981\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0906357170269454\n",
      "MAE: 0.883070063089981\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0929160056380058\n",
      "MAE: 0.8849485318533212\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0929160056380058\n",
      "MAE: 0.8849485318533212\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0929160056380058\n",
      "MAE: 0.8849485318533212\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0929160056380058\n",
      "MAE: 0.8849485318533212\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.093522289042178\n",
      "MAE: 0.885560457283802\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.093522289042178\n",
      "MAE: 0.885560457283802\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.093522289042178\n",
      "MAE: 0.885560457283802\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.093522289042178\n",
      "MAE: 0.885560457283802\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0936543706119077\n",
      "MAE: 0.8856980219154605\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0936543706119077\n",
      "MAE: 0.8856980219154605\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0936543706119077\n",
      "MAE: 0.8856980219154605\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0936543706119077\n",
      "MAE: 0.8856980219154605\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0937460483979955\n",
      "MAE: 0.8857857786632426\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0937460483979955\n",
      "MAE: 0.8857857786632426\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0937460483979955\n",
      "MAE: 0.8857857786632426\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0937460483979955\n",
      "MAE: 0.8857857786632426\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0937519033710519\n",
      "MAE: 0.8857905222712305\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0937519033710519\n",
      "MAE: 0.8857905222712305\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0937519033710519\n",
      "MAE: 0.8857905222712305\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0937519033710519\n",
      "MAE: 0.8857905222712305\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0937625831948818\n",
      "MAE: 0.885802381291201\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0937625831948818\n",
      "MAE: 0.885802381291201\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0937625831948818\n",
      "MAE: 0.885802381291201\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0937625831948818\n",
      "MAE: 0.885802381291201\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0937618784381473\n",
      "MAE: 0.8858000094872069\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0937618784381473\n",
      "MAE: 0.8858000094872069\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0937618784381473\n",
      "MAE: 0.8858000094872069\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0937618784381473\n",
      "MAE: 0.8858000094872069\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0937618784381473\n",
      "MAE: 0.8858000094872069\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0937618784381473\n",
      "MAE: 0.8858000094872069\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0937618784381473\n",
      "MAE: 0.8858000094872069\n",
      "\n",
      "\n",
      "Movie with ID 40697.0 not found\n",
      "\n",
      "Evaluation results for all models:\n",
      "RMSE: 1.0937618784381473\n",
      "MAE: 0.8858000094872069\n",
      "\n",
      "\n",
      "Optimale Gewichte: [0.33333249 0.33333414 0.33333337]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def find_optimal_weights_long():\n",
    "\n",
    "    # Startwerte für die Gewichte\n",
    "    initial_weights = np.array([1.0, 1.0, 1.0])\n",
    "\n",
    "    # Optimierung durchführen\n",
    "    result = minimize(\n",
    "        _evaluate_all,\n",
    "        initial_weights,\n",
    "        bounds=[(0, None), (0, None), (0, None)],\n",
    "    )\n",
    "\n",
    "    # Optimale Gewichte\n",
    "    optimal_weights = result.x / np.sum(\n",
    "        result.x\n",
    "    )  # Normieren der Gewichte, sodass sie sich auf 1 summieren\n",
    "    return optimal_weights\n",
    "\n",
    "\n",
    "# Optimale Gewichte berechnen\n",
    "optimal_weights = find_optimal_weights_long()\n",
    "print(\"Optimale Gewichte:\", optimal_weights)\n",
    "\n",
    "# Optimale Gewichte: [0.33333249 0.33333414 0.33333337] -> TODO: Überprüfen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimale Gewichte (MAE): [0.00000000e+00 5.21944168e-17 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def find_optimal_weights_mae(\n",
    "    mae_model_content_based, mae_model_neighborhood, mae_model_matrix_factorization\n",
    "):\n",
    "    def combined_mae(weights, maes):\n",
    "        # Berechne den gewichteten MAE\n",
    "        weighted_mae = np.sum(weights * maes) / np.sum(weights)\n",
    "        return weighted_mae\n",
    "\n",
    "    # Startwerte für die Gewichte\n",
    "    initial_weights = np.array([1.0, 1.0, 1.0])\n",
    "\n",
    "    # MAE-Werte der Modelle in ein Array packen\n",
    "    maes = np.array(\n",
    "        [\n",
    "            mae_model_content_based,\n",
    "            mae_model_neighborhood,\n",
    "            mae_model_matrix_factorization,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Optimierung durchführen\n",
    "    result = minimize(\n",
    "        combined_mae,\n",
    "        initial_weights,\n",
    "        args=(maes,),\n",
    "        bounds=[(0, None), (0, None), (0, None)],\n",
    "    )\n",
    "\n",
    "    # Optimale Gewichte\n",
    "    optimal_weights = result.x / np.sum(\n",
    "        result.x\n",
    "    )  # Normieren der Gewichte, sodass sie sich auf 1 summieren\n",
    "    return optimal_weights\n",
    "\n",
    "\n",
    "# Beispiel-MAE-Werte der einzelnen Modelle\n",
    "mae_model_content_based = 1.39\n",
    "mae_model_neighborhood = 0.87\n",
    "mae_model_matrix_factorization = 0.84\n",
    "\n",
    "# Optimale Gewichte berechnen\n",
    "optimal_weights_mae = find_optimal_weights_mae(\n",
    "    mae_model_content_based, mae_model_neighborhood, mae_model_matrix_factorization\n",
    ")\n",
    "print(\"Optimale Gewichte (MAE):\", optimal_weights_mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
